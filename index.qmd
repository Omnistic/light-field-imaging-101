---
title: 'Light-Field Imaging 101'
subtitle: 'A comprehensive introduction to unfocused light-field imaging (plenoptic 1.0)'
author: 'David Nguyen'
date: last-modified
date-format: 'MMMM D, YYYY'
bibliography: references.bib
csl: ieee.csl
jupyter: python3
---

# Intended Audience

This guide aims to expand upon existing unfocused light-field (plenoptic 1.0) imaging learning material by providing detailed Python implementations of light-field image processing along with examples. The light-field image processing workflow closely follows that of the MATLAB-based Light-Field Imaging Toolkit [@bolan2016light], but leverages Python's open-source ecosystem and Quarto's enhanced capabilities for visualization and LaTeX formula integration.

By focusing specifically on the image processing aspects, this guide helps readers better understand the technical limitations and practical considerations of light-field imaging techniques. This guide assumes the reader is familiar with unfocused light-field imaging. Such an understanding can be achieved by browsing [plenoptic.info](https://www.plenoptic.info/) or reading the unfocused light-field part of the Light-Field Camera Working Principles chapter (Pages 11-25) of the book Development and Application of Light-Field Cameras in Fluid Measurements [@shi2023development].

# Preprocessing

## Raw Images

To illustrate light-field image processing concepts, a synthetic unfocused light-field image was generated and is shown in @fig-unfocused-light-field. The image describes the raw pixel intensities as recorded by an unfocused light-field camera. Every lenslet of the camera projects the incident radiance into a defocused intensity distribution pattern. This manifests as a spatially constrained blur where the light energy from each microlens is distributed across multiple sensor pixels rather than being concentrated at the expected conjugate position. The image was generated using a commercial ray tracing software (OpticStudio, ANSYS).

::: {#fig-unfocused-light-field .column-page style='text-align: center;'}
```{python}
import tifffile
import plotly.express as px

raw_light_field_image = tifffile.imread('raw-light-field.tif')

fig = px.imshow(
    raw_light_field_image,
    color_continuous_scale='gray',
    aspect='equal'
)

fig.update_layout(
    xaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False),
    yaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False)
)

fig.show()
```
Synthetic unfocused light-field image. The hexagonal patterning in the image is characteristic of the projection process by the microlens array.
:::

## Microlens Array Structure

The unfocused light-field camera model implemented in this investigation utilizes a hexagonal microlens array configuration for two primary reasons. First, hexagonal microlens arrays provide optimal spatial packing efficiency, thereby maximizing the effective sensor area utilization. Second, the hexagonal pattern introduces additional computational complexity in light-field image processing algorithms—specifically in sampling pattern interpolation and spatial frequency analysis—that merits thorough examination within this methodological framework.

The hexagonal microlens array has 51 × 51 complete lenslets. This core array is supplemented with partial lenslets along the periphery to achieve an overall rectangular shape. The total number of elements in the array is 2&thinsp;729, which corresponds to the expected number of spots in the calibration image.

## Calibration

The calibration process seeks to pinpoint the centroid of each lenslet's corresponding sensor region. A calibration image is acquired with the main lens's aperture reduced to a minimum. The resulting calibration image consist of an array of small bright spots as shown in @fig-calibration.

::: {#fig-calibration .column-page style='text-align: center;'}
```{python}
import tifffile
import plotly.express as px

calibration_image = tifffile.imread('calibration.tif')

fig = px.imshow(
    calibration_image,
    color_continuous_scale='gray',
    aspect='equal'
)

fig.update_layout(
    xaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False),
    yaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False)
)

fig.show()
```
Synthetic light-field calibration image. Every bright spot is indicative of the corresponding lenslet centroid on the sensor.
:::

The centroid identification process based on intensity peaks in an image is a standard image processing technique widely documented in the literature, not exclusive to light-field imaging. Since the synthetic calibration image contains no sensor noise, the calibration procedure has been intentionally simplified to emphasize conceptual clarity and streamline the explanation.

The spot centroid detection procedure consists of three main steps. First, a manual threshold is applied to the calibration image to identify potential spot locations. Second, a binary dilation operation using a disk-shaped structuring element is performed to expand these areas, ensuring that the subsequent weighted centroid calculation encompasses the full spot and its immediate surroundings. Finally, the [`scikit-image`](https://scikit-image.org/) `regionprops` function is used to calculate the intensity-weighted centroids of each spot.

```{python}
#| echo: true
from skimage import morphology
from skimage.morphology import disk
from skimage.measure import label, regionprops

# Load calibration image
calibration_image = tifffile.imread('calibration.tif')

# Apply hard-coded threshold (chosen to match the expected number of centroids)
binary_calibration = calibration_image > 16

# Perform a binary dilation to ensure coverage of the spots for the computation
# of the weighted centroid
dilated_calibration = morphology.binary_dilation(binary_calibration, disk(4))

# Create labels 
labeled_calibration = label(dilated_calibration)

# Apply regionprops
regions_calibration = regionprops(labeled_calibration, intensity_image=calibration_image)

# Compute weighted centroids location
centroids = [region.centroid_weighted for region in regions_calibration]

print('Number of spots detected:', len(centroids))
```

```{python}
import numpy as np
import plotly.graph_objects as go

def get_roi(image, center, half_size):
    y, x = center
    return image[y-half_size:y+half_size, x-half_size:x+half_size]

one_centroid = np.array(centroids[500])
rounded_centroid = one_centroid.astype(int)
roi_half_size = 10

calibration_roi = get_roi(calibration_image, rounded_centroid, roi_half_size)
dilated_roi = get_roi(dilated_calibration, rounded_centroid, roi_half_size)

fig = px.imshow(
    np.stack([calibration_roi, dilated_roi], axis=0),
    color_continuous_scale='gray',
    aspect='equal',
    animation_frame=0
)
fig.add_trace(
    go.Scatter(
        x=[one_centroid[0]-rounded_centroid[0]+roi_half_size],
        y=[one_centroid[1]-rounded_centroid[1]+roi_half_size],
        marker=dict(
            size=20,
            line_width=5,
            symbol='x-thin'
        )
    )
)
fig.update_layout(
    coloraxis_showscale=False,
    dragmode=False,
    xaxis=dict(
        showticklabels=False, 
        showgrid=False, 
        zeroline=False, 
        visible=False,
        fixedrange=True
    ),
    yaxis=dict(
        showticklabels=False, 
        showgrid=False, 
        zeroline=False, 
        visible=False,
        fixedrange=True
    ),
)
fig.layout.sliders[0].steps[0].label = 'Calibration ROI'
fig.layout.sliders[0].steps[1].label = 'Thresholded and dilated ROI'
fig.show()
```
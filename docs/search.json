[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Light-Field Imaging 101",
    "section": "",
    "text": "This guide aims to expand upon existing unfocused light-field (plenoptic 1.0) imaging learning material by providing detailed Python implementations of light-field image processing along with examples. The light-field image processing workflow closely follows that of the MATLAB-based Light-Field Imaging Toolkit [1], but leverages Python’s open-source ecosystem and Quarto’s enhanced capabilities for visualization and LaTeX formula integration.\nBy focusing specifically on the image processing aspects, this guide helps readers better understand the technical limitations and practical considerations of light-field imaging techniques. This guide assumes the reader is familiar with unfocused light-field imaging. Such an understanding can be achieved by browsing plenoptic.info or reading the unfocused light-field part of the Light-Field Camera Working Principles chapter (Pages 11-25) of the book Development and Application of Light-Field Cameras in Fluid Measurements [2]."
  },
  {
    "objectID": "index.html#raw-images",
    "href": "index.html#raw-images",
    "title": "Light-Field Imaging 101",
    "section": "2.1 Raw Images",
    "text": "2.1 Raw Images\nTo illustrate light-field image processing concepts, a synthetic unfocused light-field image was generated and is shown in Figure 1. The image describes the raw pixel intensities as recorded by an unfocused light-field camera. Every lenslet of the camera projects the incident radiance into a defocused intensity distribution pattern. This manifests as a spatially constrained blur where the light energy from each microlens is distributed across multiple sensor pixels rather than being concentrated at the expected conjugate position. The image was generated using a commercial ray tracing software (OpticStudio, ANSYS).\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\nFigure 1: Synthetic unfocused light-field image. The hexagonal patterning in the image is characteristic of the projection process by the microlens array."
  },
  {
    "objectID": "index.html#sec-mla",
    "href": "index.html#sec-mla",
    "title": "Light-Field Imaging 101",
    "section": "2.2 Microlens Array Structure",
    "text": "2.2 Microlens Array Structure\nThe unfocused light-field camera model implemented in this investigation utilizes a hexagonal microlens array configuration for two primary reasons. First, hexagonal microlens arrays provide optimal spatial packing efficiency, thereby maximizing the effective sensor area utilization. Second, the hexagonal pattern introduces additional computational complexity in light-field image processing algorithms—specifically in sampling pattern interpolation and spatial frequency analysis—that merits thorough examination within this methodological framework.\nThe hexagonal microlens array has 51 × 51 complete lenslets. This core array is supplemented with partial lenslets along the periphery to achieve an overall rectangular shape. The total number of elements in the array is 2 729, which corresponds to the expected number of spots in the calibration image."
  },
  {
    "objectID": "index.html#calibration",
    "href": "index.html#calibration",
    "title": "Light-Field Imaging 101",
    "section": "2.3 Calibration",
    "text": "2.3 Calibration\nThe calibration process seeks to pinpoint the centroid of each lenslet’s corresponding sensor region. A calibration image is acquired with the main lens’s aperture reduced to a minimum. The resulting calibration image consist of an array of small bright spots as shown in Figure 2.\n\n\n\n\n\n                            \n                                            \n\n\n\n\nFigure 2: Synthetic light-field calibration image. Every bright spot is indicative of the corresponding lenslet centroid on the sensor.\n\n\n\nThe centroid identification process based on intensity peaks in an image is a standard image processing technique widely documented in the literature, not exclusive to light-field imaging. Since the synthetic calibration image contains no sensor noise, the calibration procedure has been intentionally simplified to emphasize conceptual clarity and streamline the explanation.\nThe spot centroid detection procedure consists of three main steps. First, a manual threshold is applied to the calibration image to identify potential spot locations. Second, a binary dilation operation using a disk-shaped structuring element is performed to expand these areas, ensuring that the subsequent weighted centroid calculation encompasses the full spot and its immediate surroundings. Finally, the scikit-image regionprops function is used to calculate the intensity-weighted centroids of each spot.\n\n\nCode\nfrom skimage import morphology\nfrom skimage.morphology import disk\nfrom skimage.measure import label, regionprops\n\n# Load calibration image\ncalibration_image = tifffile.imread('calibration.tif')\n\n# Apply hard-coded threshold (chosen to match the expected number of centroids)\nbinary_calibration = calibration_image &gt; 16\n\n# Perform a binary dilation to ensure coverage of the spots for the computation\n# of the weighted centroid\ndilated_calibration = morphology.binary_dilation(binary_calibration, disk(4))\n\n# Create labels \nlabeled_calibration = label(dilated_calibration)\n\n# Apply regionprops\nregions_calibration = regionprops(labeled_calibration, intensity_image=calibration_image)\n\n# Compute weighted centroids location\ncentroids = [region.centroid_weighted for region in regions_calibration]\n\nprint(f'Number of centroids detected: {len(centroids):,}'.replace(',', '\\u2009'))\n\n\nNumber of centroids detected: 2 729\n\n\nThe threshold value was manually selected to ensure the number of detected centroids matches the total lenslet count (2 729) as described in Section Section 2.2.\nThe centroid localization procedure is demonstrated in Figure 3 using a representative calibration spot. The figure displays two frames: the first showing a magnified view of an individual calibration spot, and the second showing the binary mask generated through thresholding and morphological dilation operations. The calculated weighted centroid position, determined by applying the mask to the intensity distribution of the spot, is indicated by a pink cross marker.\n\n\n\n\n\n                            \n                                            \n\n\n\n\nFigure 3: Close-up of a calibration spot showing the centroid identification process. Toggle view shows: ‘Calibration ROI’ (original spot from calibration image) or ‘Thresholded and dilated ROI’ (processed mask). Pink cross indicating the weighted centroid location."
  },
  {
    "objectID": "index.html#reshaping",
    "href": "index.html#reshaping",
    "title": "Light-Field Imaging 101",
    "section": "2.4 Reshaping",
    "text": "2.4 Reshaping\nThe next step is to reshape the 2D light-field image into a 4D light-field array."
  }
]